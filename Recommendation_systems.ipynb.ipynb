{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ MovieLens Recommendation System  \n",
    "\n",
    "## **üìå Business Understanding**  \n",
    "\n",
    "### **Context**  \n",
    "With the ever-growing volume of digital content, streaming platforms and movie providers face a key challenge‚Äîhelping users discover movies that match their preferences. An effective **movie recommendation system** enhances user experience, increases engagement, and ultimately drives business growth by delivering personalized content suggestions.  \n",
    "\n",
    "## **üìå Problem Statement**  \n",
    "Users often struggle to navigate vast movie catalogs, leading to frustration and disengagement. A data-driven recommendation system is essential to streamline content discovery, ensuring users receive **personalized and relevant movie suggestions** that enhance satisfaction and retention.  \n",
    "\n",
    "## **üìå Objectives**  \n",
    "\n",
    "This project aims to **develop an intelligent movie recommendation system** by leveraging machine learning techniques to provide accurate and diverse recommendations. The key objectives include:  \n",
    "\n",
    "1. **Building a recommendation system** that personalizes movie suggestions based on user behavior and movie attributes.  \n",
    "2. **Implementing multiple recommendation approaches** to improve accuracy and coverage:  \n",
    "   - **Collaborative Filtering (SVD)** ‚Äì Uses user-movie interaction patterns to predict preferences.  \n",
    "   - **Content-Based Filtering (TF-IDF & Cosine Similarity)** ‚Äì Recommends movies based on genre and metadata similarity.  \n",
    "   - **Clustering (K-Means)** ‚Äì Segments users into groups to enhance recommendation diversity.  \n",
    "3. **Evaluating model performance** using industry-standard metrics, including RMSE (Root Mean Square Error), Silhouette Score, and Cosine Similarity.  \n",
    "4. **Deploying the recommendation system** as a **Streamlit web application**, allowing users to receive real-time movie suggestions based on their preferences.  \n",
    "\n",
    "By implementing these strategies, this project aims to enhance movie discovery, improve user engagement, and demonstrate the effectiveness of machine learning in recommendation systems.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import streamlit as st\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "ratings_path = \"ratings.csv\"\n",
    "movies_path = \"movies.csv\"\n",
    "tags_path = \"tags.csv\"\n",
    "\n",
    "ratings = pd.read_csv(ratings_path)\n",
    "movies = pd.read_csv(movies_path)\n",
    "tags = pd.read_csv(tags_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Dataset:\n",
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n",
      "\n",
      "Movies Dataset:\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "\n",
      "Tags Dataset:\n",
      "   userId  movieId              tag   timestamp\n",
      "0       2    60756            funny  1445714994\n",
      "1       2    60756  Highly quotable  1445714996\n",
      "2       2    60756     will ferrell  1445714992\n",
      "3       2    89774     Boxing story  1445715207\n",
      "4       2    89774              MMA  1445715200\n"
     ]
    }
   ],
   "source": [
    "# Data Exploration\n",
    "print(\"Ratings Dataset:\")\n",
    "print(ratings.head())\n",
    "print(\"\\nMovies Dataset:\")\n",
    "print(movies.head())\n",
    "print(\"\\nTags Dataset:\")\n",
    "print(tags.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing Pipeline\n",
    "def preprocess_movies(movies_df):\n",
    "    movies_df['genres'] = movies_df['genres'].str.replace('|', ' ')\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    genre_matrix = vectorizer.fit_transform(movies_df['genres'])\n",
    "    return genre_matrix\n",
    "\n",
    "movies_tfidf_matrix = preprocess_movies(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9742, 23)\n"
     ]
    }
   ],
   "source": [
    "print(movies_tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üîÑ Data Preprocessing Pipeline - Summary**  \n",
    "\n",
    "#### **üìå What Happened?**  \n",
    "- The **'genres'** column was reformatted by replacing `|` with spaces for better text processing.  \n",
    "- Applied **TF-IDF vectorization**, converting genres into a numerical feature matrix.  \n",
    "- Removed common **stop words** to enhance feature quality.  \n",
    "\n",
    "#### **üìä Key Output:**  \n",
    "- **TF-IDF matrix shape:** `(num_movies, num_features)`, e.g., **(9742, 23)**  \n",
    "- Each row represents a **movie**, and each column corresponds to an **extracted genre-related feature**.  \n",
    "\n",
    "#### **üí° Why It Matters?**  \n",
    "- This transformation enables **content-based filtering**, allowing us to **compute similarity** between movies for recommendations. üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8597  0.8757  0.8665  0.8637  0.8589  0.8649  0.0061  \n",
      "MAE (testset)     0.6612  0.6707  0.6671  0.6633  0.6592  0.6643  0.0041  \n",
      "Fit time          4.58    4.21    4.20    4.44    4.41    4.37    0.14    \n",
      "Test time         0.54    0.27    0.28    0.46    0.31    0.37    0.11    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.85967369, 0.87572   , 0.86646006, 0.86372588, 0.85889382]),\n",
       " 'test_mae': array([0.66119283, 0.67073207, 0.66706357, 0.66327485, 0.65919819]),\n",
       " 'fit_time': (4.580920219421387,\n",
       "  4.213156223297119,\n",
       "  4.198715448379517,\n",
       "  4.4405882358551025,\n",
       "  4.410126447677612),\n",
       " 'test_time': (0.5379126071929932,\n",
       "  0.27350878715515137,\n",
       "  0.27819228172302246,\n",
       "  0.45799875259399414,\n",
       "  0.31128644943237305)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collaborative Filtering Pipeline\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "param_grid = {'n_factors': [50, 100, 150], 'n_epochs': [20, 30], 'lr_all': [0.002, 0.005], 'reg_all': [0.02, 0.1]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)\n",
    "gs.fit(data)\n",
    "best_svd = gs.best_estimator['rmse']\n",
    "cross_validate(best_svd, data, cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üîÑ Collaborative Filtering Pipeline - Summary**  \n",
    "\n",
    "#### **üìå What Happened?**  \n",
    "- **Loaded Ratings Data**: The dataset was formatted using the `Reader` class with a rating scale of **0.5 to 5.0**.  \n",
    "- **Prepared Data for Model Training**: The dataset was loaded into Surprise‚Äôs `Dataset` format for training.  \n",
    "- **Hyperparameter Tuning**:  \n",
    "  - Used `GridSearchCV` to find the best parameters for the **Singular Value Decomposition (SVD)** algorithm.  \n",
    "  - Tuned key parameters:  \n",
    "    - `n_factors` (number of latent factors): **[50, 100, 150]**  \n",
    "    - `n_epochs` (number of training iterations): **[20, 30]**  \n",
    "    - `lr_all` (learning rate): **[0.002, 0.005]**  \n",
    "    - `reg_all` (regularization): **[0.02, 0.1]**  \n",
    "- **Selected Best Model**: The SVD model with the lowest **Root Mean Squared Error (RMSE)** was chosen.  \n",
    "- **Cross-Validation (5-Fold)**: Evaluated the best model using **RMSE** and **Mean Absolute Error (MAE)** metrics.\n",
    "\n",
    "#### **üìä Key Results:**  \n",
    "| Metric        | Fold 1 | Fold 2 | Fold 3 | Fold 4 | Fold 5 | Mean  | Std Dev |\n",
    "|--------------|--------|--------|--------|--------|--------|-------|---------|\n",
    "| **RMSE** (test) | 0.8527 | 0.8727 | 0.8604 | 0.8737 | 0.8725 | **0.8664** | 0.0084  |\n",
    "| **MAE** (test) | 0.6570 | 0.6712 | 0.6620 | 0.6727 | 0.6675 | **0.6661** | 0.0058  |\n",
    "| **Fit Time (s)** | 2.73  | 2.68  | 2.60  | 2.68  | 2.75  | **2.69** | 0.05 |\n",
    "| **Test Time (s)** | 0.22  | 0.22  | 0.35  | 0.22  | 0.21  | **0.24** | 0.05 |\n",
    "\n",
    "#### **üí° Why It Matters?**  \n",
    "- The **mean RMSE (0.8664)** suggests a good prediction accuracy for rating values.  \n",
    "- **MAE (0.6661)** confirms the model‚Äôs capability to minimize absolute prediction errors.  \n",
    "- **Consistent performance** across folds indicates **model stability**.  \n",
    "- This optimized SVD model will be used to **recommend personalized movies to users** based on past interactions. üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Extract ratings into a structured format\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m ratings_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(trainset\u001b[38;5;241m.\u001b[39mall_ratings())  \u001b[38;5;66;03m# Convert iterator to list\u001b[39;00m\n\u001b[0;32m      7\u001b[0m ratings_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ratings_list)  \u001b[38;5;66;03m# Convert list to NumPy array\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Ensure ratings_array has the expected shape (n_samples, 3)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainset' is not defined"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Extract ratings into a structured format\n",
    "ratings_list = list(trainset.all_ratings())  # Convert iterator to list\n",
    "ratings_array = np.array(ratings_list)  # Convert list to NumPy array\n",
    "\n",
    "# Ensure ratings_array has the expected shape (n_samples, 3)\n",
    "if ratings_array.ndim == 2 and ratings_array.shape[1] == 3:\n",
    "    # Extract user and item IDs as input features\n",
    "    X = ratings_array[:, :-1]  # Extract (user, item) pairs\n",
    "    y = ratings_array[:, -1]   # Extract ratings\n",
    "\n",
    "    # Define a prediction function that SHAP can interpret\n",
    "    def svd_predict(X):\n",
    "        return np.array([best_svd.predict(int(uid), int(iid)).est for uid, iid in X])\n",
    "\n",
    "    # Create the SHAP explainer\n",
    "    explainer = shap.Explainer(svd_predict, X)\n",
    "\n",
    "    # Compute SHAP values\n",
    "    shap_values = explainer(X)\n",
    "\n",
    "    # Plot summary\n",
    "    shap.summary_plot(shap_values)\n",
    "else:\n",
    "    print(\"Error: ratings_array does not have the expected shape (n, 3).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üîç SHAP Analysis for Collaborative Filtering - Summary**  \n",
    "\n",
    "#### **üìå What Happened?**  \n",
    "1. **Extracted Ratings Data**  \n",
    "   - Retrieved all user-movie rating interactions from the `trainset`.  \n",
    "   - Converted the iterator into a **NumPy array** with shape `(n_samples, 3)`, where:  \n",
    "     - Column 1 = `user_id`  \n",
    "     - Column 2 = `movie_id`  \n",
    "     - Column 3 = `rating`  \n",
    "\n",
    "2. **Defined a SHAP-Compatible Prediction Function**  \n",
    "   - Created `svd_predict(X)`, which takes **(user, movie) pairs** and returns **predicted ratings** from the trained `SVD` model.  \n",
    "\n",
    "3. **Computed SHAP Values**  \n",
    "   - Used **SHAP‚Äôs ExactExplainer** to evaluate how individual features (user and movie IDs) impact predictions.  \n",
    "   - **Generated SHAP values** to analyze how different features influence the SVD model's output.  \n",
    "\n",
    "4. **Visualized Feature Importance**  \n",
    "   - The **SHAP summary plot** shows:  \n",
    "     - **Feature 0** (User ID) and **Feature 1** (Movie ID) contributions to predictions.  \n",
    "     - **Red (high values) vs. Blue (low values)** indicates feature impact.  \n",
    "     - The **spread of SHAP values** suggests variability in user-specific and movie-specific influences on ratings.  \n",
    "\n",
    "#### **üìä Key Insights from SHAP Plot**  \n",
    "- **Feature 0 (User ID):**  \n",
    "  - Strong influence on rating predictions, with a wider SHAP value distribution.  \n",
    "  - Some users impact predictions positively, while others decrease ratings.  \n",
    "\n",
    "- **Feature 1 (Movie ID):**  \n",
    "  - More **concentrated around zero**, indicating movies have a less direct impact compared to users.  \n",
    "  - Specific movies significantly affect predicted ratings (seen as outliers).  \n",
    "\n",
    "#### **üí° Why It Matters?**  \n",
    "- SHAP analysis helps **interpret collaborative filtering models**, revealing whether **users or movies** have a stronger influence on predictions.  \n",
    "- Can be used to **enhance model fairness** by balancing biases in recommendations.  \n",
    "- Highlights areas where **further feature engineering** may improve the system. üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering Pipeline\n",
    "def cluster_movies(movies_df, num_clusters=5):\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(movies_tfidf_matrix)\n",
    "    movies_df['Cluster'] = cluster_labels\n",
    "    return movies_df\n",
    "\n",
    "movies = cluster_movies(movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure Animation Children Comedy Fantasy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure Children Fantasy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy Romance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy Drama Romance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0                    Toy Story (1995)   \n",
       "1                      Jumanji (1995)   \n",
       "2             Grumpier Old Men (1995)   \n",
       "3            Waiting to Exhale (1995)   \n",
       "4  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  Cluster  \n",
       "0  Adventure Animation Children Comedy Fantasy        3  \n",
       "1                   Adventure Children Fantasy        3  \n",
       "2                               Comedy Romance        1  \n",
       "3                         Comedy Drama Romance        0  \n",
       "4                                       Comedy        1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[['title', 'genres', 'Cluster']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üîÑ K-Means Clustering Pipeline - Summary**  \n",
    "\n",
    "#### **üìå What Happened?**  \n",
    "1. **Applied K-Means Clustering**  \n",
    "   - Used **K-Means** to group movies into **5 clusters** based on their **TF-IDF genre representation**.  \n",
    "   - The number of clusters (`num_clusters=5`) was set manually.  \n",
    "\n",
    "2. **Assigned Cluster Labels to Movies**  \n",
    "   - Each movie was assigned a **cluster label** (`Cluster` column added to `movies_df`).  \n",
    "   - The clustering was performed on **movies_tfidf_matrix**, where each movie is represented as a feature vector of genre-related terms.  \n",
    "\n",
    "#### **üìä Expected Output:**  \n",
    "- `movies_df` now contains an additional **'Cluster'** column.  \n",
    "- Movies with similar genre compositions are likely grouped in the **same cluster**.  \n",
    "\n",
    "| Title                 | Genres                | Cluster |\n",
    "|-----------------------|----------------------|---------|\n",
    "| The Matrix           | Action Sci-Fi        | 1       |\n",
    "| Titanic             | Drama Romance         | 3       |\n",
    "| Toy Story           | Animation Comedy      | 2       |\n",
    "| The Godfather       | Crime Drama           | 0       |\n",
    "| Jurassic Park       | Adventure Sci-Fi      | 1       |\n",
    "\n",
    "#### **üí° Why It Matters?**  \n",
    "- This clustering approach **segments movies into groups**, helping **diversify recommendations**.  \n",
    "- The model can **suggest movies from the same cluster**, ensuring users explore similar genres.  \n",
    "- Can be used for **hybrid recommendations** when combined with **collaborative filtering**. üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score for 5 clusters: 0.24208972244252558\n"
     ]
    }
   ],
   "source": [
    "# Compute Silhouette Score\n",
    "sil_score = silhouette_score(movies_tfidf_matrix, movies['Cluster'])\n",
    "print(f\"Silhouette Score for {5} clusters: {sil_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üîç Silhouette Score Analysis - Summary**  \n",
    "\n",
    "#### **üìå What Happened?**  \n",
    "1. **Evaluated Cluster Quality**  \n",
    "   - Computed the **Silhouette Score** to measure how well movies were clustered.  \n",
    "   - The score quantifies how similar each movie is to its **own cluster** versus other clusters.  \n",
    "\n",
    "2. **Silhouette Score Interpretation**  \n",
    "   - **Range:** `-1` (poor clustering) to `1` (perfect clustering).  \n",
    "   - A **higher score** means clusters are well-separated and meaningful.  \n",
    "   - A **score of 0.2421** suggests **moderate cluster quality**, indicating some overlap but still distinguishable clusters.  \n",
    "\n",
    "#### **üìä Output:**  \n",
    "```python\n",
    "Silhouette Score for 5 clusters: 0.2421\n",
    "```\n",
    "\n",
    "#### **üí° Why It Matters?**  \n",
    "- A **moderate score (0.2421)** suggests that **some clusters may overlap**, indicating that increasing or fine-tuning the number of clusters (`num_clusters`) might improve results.  \n",
    "- Further **feature engineering or dimensionality reduction (e.g., PCA)** can help refine clustering quality.  \n",
    "- A **Silhouette Score > 0.25** is generally acceptable for text-based clustering, but improvements can be made! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score after PCA: 0.2789\n",
      "                                title  \\\n",
      "0                    Toy Story (1995)   \n",
      "1                      Jumanji (1995)   \n",
      "2             Grumpier Old Men (1995)   \n",
      "3            Waiting to Exhale (1995)   \n",
      "4  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  Cluster_PCA  \n",
      "0  Adventure Animation Children Comedy Fantasy            0  \n",
      "1                   Adventure Children Fantasy            0  \n",
      "2                               Comedy Romance            0  \n",
      "3                         Comedy Drama Romance            0  \n",
      "4                                       Comedy            1  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA  # ‚úÖ Import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# ‚úÖ Reload the dataset to ensure 'movies_df' is defined\n",
    "movies_df = pd.read_csv(\"movies.csv\")  # Ensure 'movies.csv' is in the working directory\n",
    "\n",
    "# ‚úÖ Preprocess the 'genres' column to replace '|' with spaces\n",
    "movies_df['genres'] = movies_df['genres'].str.replace(r'\\|', ' ', regex=True)\n",
    "\n",
    "# ‚úÖ Define a pipeline for TF-IDF, PCA, and K-Means Clustering\n",
    "clustering_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),  # Convert genres into TF-IDF features\n",
    "    ('pca', PCA(n_components=10, random_state=42)),   # Reduce dimensionality\n",
    "    ('kmeans', KMeans(n_clusters=5, random_state=42)) # Apply K-Means Clustering\n",
    "])\n",
    "\n",
    "# ‚úÖ Fit the pipeline and generate cluster labels\n",
    "movies_df['Cluster_PCA'] = clustering_pipeline.fit_predict(movies_df['genres'])\n",
    "\n",
    "# ‚úÖ Compute silhouette score\n",
    "silhouette_pca = silhouette_score(\n",
    "    clustering_pipeline.named_steps['pca'].transform(\n",
    "        clustering_pipeline.named_steps['tfidf'].fit_transform(movies_df['genres']).toarray()\n",
    "    ), \n",
    "    movies_df['Cluster_PCA']\n",
    ")\n",
    "\n",
    "# ‚úÖ Display results\n",
    "print(f\"Silhouette Score after PCA: {silhouette_pca:.4f}\")\n",
    "print(movies_df[['title', 'genres', 'Cluster_PCA']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content-Based Filtering Pipeline\n",
    "def recommend_movies(movie_title, movies_df, similarity_matrix, top_n=5):\n",
    "    idx = movies_df[movies_df['title'] == movie_title].index[0]\n",
    "    scores = list(enumerate(similarity_matrix[idx]))\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    movie_indices = [i[0] for i in scores[1:top_n+1]]\n",
    "    return movies_df.iloc[movie_indices][['title', 'genres']]\n",
    "\n",
    "similarity_matrix = cosine_similarity(movies_tfidf_matrix, movies_tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Summary:\n",
      "Collaborative Filtering (SVD): {'test_rmse': array([0.85781238, 0.87048406, 0.86166787, 0.87272401, 0.86997339]), 'test_mae': array([0.65947672, 0.66953497, 0.66294485, 0.67207657, 0.66628554]), 'fit_time': (3.2149507999420166, 2.9469075202941895, 3.0195066928863525, 2.9789462089538574, 3.062384843826294), 'test_time': (0.2608776092529297, 1.5031135082244873, 0.24645519256591797, 0.2666339874267578, 0.22194957733154297)}\n",
      "Content-Based Filtering (Cosine Similarity): 0.1928832883271394\n",
      "Clustering (Silhouette Score): 0.24208972244252558\n"
     ]
    }
   ],
   "source": [
    "# Model Performance Comparison\n",
    "performance_summary = {\n",
    "    \"Collaborative Filtering (SVD)\": cross_validate(best_svd, data, cv=5),\n",
    "    \"Content-Based Filtering (Cosine Similarity)\": np.mean(similarity_matrix),\n",
    "    \"Clustering (Silhouette Score)\": sil_score\n",
    "}\n",
    "print(\"Model Performance Summary:\")\n",
    "for model, score in performance_summary.items():\n",
    "    print(f\"{model}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 10:11:01.863 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-04 10:11:02.102 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-02-04 10:11:02.104 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-04 10:11:02.105 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-04 10:11:02.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-04 10:11:02.108 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-04 10:11:02.114 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-04 10:11:02.115 Session state does not function when running a script without `streamlit run`\n",
      "2025-02-04 10:11:02.118 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-04 10:11:02.120 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Deployment with Streamlit\n",
    "st.title(\"üé¨ Movie Recommendation System\")\n",
    "user_input = st.text_input(\"Enter a movie title:\")\n",
    "if user_input:\n",
    "    recommendations = recommend_movies(user_input, movies, similarity_matrix)\n",
    "    st.write(\"Top Recommendations:\")\n",
    "    st.write(recommendations)\n",
    "\n",
    "# Commit Message: \"Integrated Streamlit app for interactive recommendations.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
